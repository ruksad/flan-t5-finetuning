{"cells":[{"cell_type":"code","execution_count":13,"id":"60873746","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60873746","executionInfo":{"status":"ok","timestamp":1763784361716,"user_tz":-330,"elapsed":5002,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}},"outputId":"b6f8dded-e2f9-4560-f43c-f3395ee15d15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers>=4.57.1 in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n","Requirement already satisfied: bert-score in /usr/local/lib/python3.12/dist-packages (0.3.13)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n","Requirement already satisfied: peft>=0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.57.1) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft>=0.18.0) (5.9.5)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.57.1) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.57.1) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.57.1) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.57.1) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.57.1) (2025.11.12)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.3.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n"]}],"source":["!pip install \"transformers>=4.57.1\" sentencepiece torch evaluate bert-score scikit-learn rouge-score \"peft>=0.18.0\"  datasets accelerate tensorboard"]},{"cell_type":"code","execution_count":14,"id":"e86f2714","metadata":{"id":"e86f2714","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763784361728,"user_tz":-330,"elapsed":10,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}},"outputId":"a5a2a935-c9e4-43ae-9850-bcd16cd26c17"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":14}],"source":["import os, random, numpy as np, torch, json, warnings\n","from torch.utils.tensorboard import SummaryWriter\n","from datasets import load_dataset\n","import evaluate # Import the evaluate library\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSeq2SeqLM,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    set_seed,\n",")\n","from peft import (\n","    PromptTuningConfig,\n","    LoraConfig,\n","    PrefixTuningConfig,\n","    get_peft_model,\n",")\n","\n","warnings.filterwarnings(\"ignore\")\n","set_seed(42)                     # reproducibility\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"OWoIlXKb3exd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763784363459,"user_tz":-330,"elapsed":1729,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}},"outputId":"13cfa289-bc03-4d90-9b3a-d9c6a6150a1d"},"id":"OWoIlXKb3exd","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":16,"id":"32af8a60","metadata":{"id":"32af8a60","executionInfo":{"status":"ok","timestamp":1763784363463,"user_tz":-330,"elapsed":2,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}}},"outputs":[],"source":["def get_cls_metrics():\n","    metric = evaluate.load(\"accuracy\")\n","    f1_metric = evaluate.load(\"f1\")\n","    def compute(pred):\n","        preds = np.argmax(pred.predictions, axis=1)\n","        refs  = pred.label_ids\n","        acc   = metric.compute(predictions=preds, references=refs)[\"accuracy\"]\n","        f1    = f1_metric.compute(predictions=preds, references=refs, average=\"binary\")[\"f1\"]\n","        return {\"accuracy\": acc, \"f1\": f1}\n","    return compute\n","\n","def get_sum_metrics():\n","    rouge = evaluate.load(\"rouge\")\n","    def compute(pred):\n","        decoded_preds = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n","        decoded_refs  = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n","        result = rouge.compute(predictions=decoded_preds, references=decoded_refs, use_stemmer=True)\n","        # keep only the mid F1 scores\n","        result = {k: round(v.mid.fmeasure * 100, 2) for k, v in result.items()}\n","        return result\n","    return compute"]},{"cell_type":"code","execution_count":17,"id":"9b99cefd","metadata":{"id":"9b99cefd","executionInfo":{"status":"ok","timestamp":1763784363468,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}}},"outputs":[],"source":["def common_training_args(output_dir):\n","    from types import SimpleNamespace\n","    # Minimal config used by the manual training loop\n","    return SimpleNamespace(\n","        output_dir=output_dir,\n","        per_device_train_batch_size=8,\n","        per_device_eval_batch_size=8,\n","        learning_rate=3e-4,\n","        num_train_epochs=3,\n","        weight_decay=0.01,\n","        logging_steps=50,\n","        fp16=True,\n","        seed=42,\n","        dataloader_drop_last=False,\n","    )"]},{"cell_type":"code","execution_count":18,"id":"b8670f7d","metadata":{"id":"b8670f7d","executionInfo":{"status":"ok","timestamp":1763784363473,"user_tz":-330,"elapsed":4,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}}},"outputs":[],"source":["def load_cls_dataset():\n","    # GLUE SST‑2 – binary sentiment (0 = negative, 1 = positive)\n","    raw = load_dataset(\"glue\", \"sst2\")\n","    return raw[\"train\"], raw[\"validation\"]"]},{"cell_type":"code","execution_count":19,"id":"7192a97c","metadata":{"id":"7192a97c","executionInfo":{"status":"ok","timestamp":1763784363476,"user_tz":-330,"elapsed":2,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}}},"outputs":[],"source":["def cls_tokenize(batch, tokenizer):\n","    # T5 expects a text‑to‑text format, so we add a simple prompt\n","    inputs = [\"sst2: \" + txt for txt in batch[\"sentence\"]]\n","    model_inputs = tokenizer(\n","        inputs,\n","        max_length=128,\n","        truncation=True,\n","        padding=\"max_length\",\n","    )\n","    # Labels are integers 0/1 – we keep them as‑is\n","    model_inputs[\"labels\"] = batch[\"label\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":20,"id":"a10a5a93","metadata":{"id":"a10a5a93","executionInfo":{"status":"ok","timestamp":1763784363478,"user_tz":-330,"elapsed":1,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}}},"outputs":[],"source":["def train_peft_cls(peft_name, peft_cfg, train_ds, eval_ds, out_dir):\n","    tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n","    model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-small\")\n","    model = get_peft_model(model, peft_cfg)\n","    model.print_trainable_parameters()\n","    model.to(device)\n","\n","    args = common_training_args(out_dir)\n","    train_bs = args.per_device_train_batch_size\n","    eval_bs  = args.per_device_eval_batch_size\n","    lr = args.learning_rate\n","    weight_decay = args.weight_decay\n","    num_epochs = int(args.num_train_epochs)\n","\n","    def cls_collator(batch):\n","        inputs = [\"sst2: \" + ex[\"sentence\"] for ex in batch]\n","        enc = tokenizer(\n","            inputs,\n","            max_length=128,\n","            truncation=True,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\",\n","        )\n","        tgt_txt = [str(int(ex[\"label\"])) for ex in batch]\n","        with tokenizer.as_target_tokenizer():\n","            labels_tok = tokenizer(\n","                tgt_txt,\n","                max_length=4,\n","                truncation=True,\n","                padding=\"max_length\",\n","                return_tensors=\"pt\",\n","            )\n","        labels = labels_tok[\"input_ids\"]\n","        labels[labels == tokenizer.pad_token_id] = -100\n","        enc[\"labels\"] = labels\n","        return enc\n","\n","    from torch.utils.data import DataLoader\n","    train_loader = DataLoader(train_ds, batch_size=train_bs, shuffle=True,  collate_fn=cls_collator)\n","    eval_loader  = DataLoader(eval_ds,  batch_size=eval_bs,  shuffle=False, collate_fn=cls_collator)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    from transformers import get_linear_schedule_with_warmup\n","    total_steps = len(train_loader) * max(1, num_epochs)\n","    warmup_steps = max(0, int(0.1 * total_steps))\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n","\n","    writer = SummaryWriter(log_dir=f\"{out_dir}/runs\")\n","\n","    # Metrics via HF load_metric\n","    acc_metric = evaluate.load(\"accuracy\")\n","    f1_metric  = evaluate.load(\"f1\")\n","\n","    for epoch in range(num_epochs):\n","        # ---------------- Train ----------------\n","        model.train()\n","        total_train_loss, n_train = 0.0, 0\n","        for batch in train_loader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            optimizer.zero_grad()\n","            out = model(**batch)\n","            loss = out.loss\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            scheduler.step()\n","            total_train_loss += loss.item() * batch[\"input_ids\"].size(0)\n","            n_train += batch[\"input_ids\"].size(0)\n","        avg_train = total_train_loss / max(1, n_train)\n","\n","        # ---------------- Eval (loss + metrics) ----------------\n","        model.eval()\n","        total_eval_loss, n_eval = 0.0, 0\n","        preds_list, refs_list = [], []\n","        with torch.no_grad():\n","            for batch in eval_loader:\n","                input_ids_cpu = batch[\"input_ids\"]\n","                attention_mask_cpu = batch[\"attention_mask\"]\n","                labels_cpu = batch[\"labels\"]\n","                batch = {k: v.to(device) for k, v in batch.items()}\n","                out = model(**batch)\n","                loss = out.loss\n","                total_eval_loss += loss.item() * batch[\"input_ids\"].size(0)\n","                n_eval += batch[\"input_ids\"].size(0)\n","                gen_ids = model.generate(\n","                    input_ids=input_ids_cpu.to(device),\n","                    attention_mask=attention_mask_cpu.to(device),\n","                    max_length=4,\n","                    num_beams=1,\n","                )\n","                decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n","                for txt, lab_seq in zip(decoded, labels_cpu):\n","                    txt_clean = txt.strip()\n","                    pred_digit = 1 if txt_clean.startswith(\"1\") else 0\n","                    ref_tokens = [t for t in lab_seq.tolist() if t != -100]\n","                    ref_text = tokenizer.decode(ref_tokens, skip_special_tokens=True).strip()\n","                    ref_digit = 1 if ref_text.startswith(\"1\") else 0\n","                    preds_list.append(pred_digit)\n","                    refs_list.append(ref_digit)\n","        avg_eval = total_eval_loss / max(1, n_eval)\n","\n","        acc = acc_metric.compute(predictions=preds_list, references=refs_list)[\"accuracy\"]\n","        f1  = f1_metric.compute(predictions=preds_list, references=refs_list, average=\"binary\")[\"f1\"]\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs} - train_loss: {avg_train:.4f} - val_loss: {avg_eval:.4f} - acc: {acc:.4f} - f1: {f1:.4f}\")\n","        writer.add_scalar(\"train/loss\", avg_train, epoch + 1)\n","        writer.add_scalar(\"val/loss\",   avg_eval,  epoch + 1)\n","        writer.add_scalar(\"val/accuracy\", acc, epoch + 1)\n","        writer.add_scalar(\"val/f1\", f1, epoch + 1)\n","        current_lr = scheduler.get_last_lr()[0]\n","        writer.add_scalar(\"lr\", current_lr, epoch + 1)\n","\n","    writer.close()\n","\n","    os.makedirs(out_dir, exist_ok=True)\n","    model.save_pretrained(out_dir)\n","    tokenizer.save_pretrained(out_dir)\n","\n","    return {\"peft\": peft_name, \"eval_loss\": avg_eval, \"accuracy\": acc, \"f1\": f1}"]},{"cell_type":"code","execution_count":null,"id":"4ae75b23","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ae75b23","outputId":"8ac65342-2050-44d3-f787-13c9372ebb82"},"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 20,480 || all params: 60,527,104 || trainable%: 0.0338\n","Epoch 1/3 - train_loss: 2.1264 - val_loss: 0.3336 - acc: 0.5092 - f1: 0.6748\n","Epoch 2/3 - train_loss: 0.4752 - val_loss: 0.3332 - acc: 0.5092 - f1: 0.6748\n","Epoch 3/3 - train_loss: 0.4009 - val_loss: 0.3317 - acc: 0.5092 - f1: 0.6748\n","trainable params: 294,912 || all params: 60,801,536 || trainable%: 0.4850\n","Epoch 1/3 - train_loss: 0.2745 - val_loss: 0.1289 - acc: 0.8991 - f1: 0.9027\n","Epoch 2/3 - train_loss: 0.0960 - val_loss: 0.1274 - acc: 0.9083 - f1: 0.9103\n","Epoch 3/3 - train_loss: 0.0864 - val_loss: 0.1247 - acc: 0.9071 - f1: 0.9093\n","trainable params: 3,424,768 || all params: 63,931,392 || trainable%: 5.3569\n"]}],"source":["train_set, val_set = load_cls_dataset()\n","\n","# 1️⃣ Prompt‑tuning\n","prompt_cfg = PromptTuningConfig(\n","    num_virtual_tokens=20,\n","    task_type=\"SEQ_2_SEQ_LM\",\n",")\n","cls_prompt = train_peft_cls(\n","    peft_name=\"Prompt\",\n","    peft_cfg=prompt_cfg,\n","    train_ds=train_set,\n","    eval_ds=val_set,\n","    out_dir=\"/content/drive/MyDrive/colab_results/cls_prompt\",\n",")\n","\n","# 2️⃣ LoRA\n","lora_cfg = LoraConfig(\n","    r=8,\n","    lora_alpha=32,\n","    target_modules=[\"q\", \"v\"],   # you can also use [\"q\",\"k\",\"v\",\"o\"]\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"SEQ_2_SEQ_LM\",\n",")\n","cls_lora = train_peft_cls(\n","    peft_name=\"LoRA\",\n","    peft_cfg=lora_cfg,\n","    train_ds=train_set,\n","    eval_ds=val_set,\n","    out_dir=\"/content/drive/MyDrive/colab_results/cls_lora\",\n",")\n","\n","# 3️⃣ Prefix‑tuning\n","prefix_cfg = PrefixTuningConfig(\n","    num_virtual_tokens=20,\n","    task_type=\"SEQ_2_SEQ_LM\",\n","    prefix_projection=True,\n","    encoder_hidden_size=512\n",")\n","cls_prefix = train_peft_cls(\n","    peft_name=\"Prefix\",\n","    peft_cfg=prefix_cfg,\n","    train_ds=train_set,\n","    eval_ds=val_set,\n","    out_dir=\"/content/drive/MyDrive/colab_results/cls_prefix\",\n",")\n","\n","# Gather results\n","cls_results = [cls_prompt, cls_lora, cls_prefix]\n","print(json.dumps(cls_results, indent=2))"]},{"cell_type":"code","source":["train_set, val_set = load_cls_dataset()\n","tmp = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-small\")\n","print(tmp.config.d_model, tmp.config.num_heads, tmp.config.d_kv)  # 512 6 64\n","\n","# 3️⃣ Prefix‑tuning (fixed for T5-small)\n","prefix_cfg = PrefixTuningConfig(\n","    task_type=\"SEQ_2_SEQ_LM\",\n","    num_virtual_tokens=20,        # Use 24, a multiple of 8 (num_attention_heads)\n","    prefix_projection= True,\n","    encoder_hidden_size=tmp.config.d_model\n",")\n","\n","cls_prefix = train_peft_cls1(\n","    peft_name=\"Prefix\",\n","    peft_cfg=prefix_cfg,\n","    train_ds=train_set,\n","    eval_ds=val_set,\n","    out_dir=\"/content/drive/MyDrive/colab_results/cls_prefix\",\n",")\n","#except RuntimeError as e:\n","#print(\"Prefix tuning failed, falling back to Prompt/LoRA only:\", e)\n","#cls_prefix = {\"peft\": \"Prefix\", \"error\": str(e)}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nvh1aoFldU6A","executionInfo":{"status":"ok","timestamp":1763789608618,"user_tz":-330,"elapsed":821287,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}},"outputId":"b8cc34e0-ec85-44d7-c85d-c388828bea66"},"id":"nvh1aoFldU6A","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["512 8 64\n","trainable params: 3,424,768 || all params: 63,931,392 || trainable%: 5.3569\n","Epoch 1/3 - train_loss: 0.2616 - val_loss: 0.1284 - acc: 0.6376 - f1: 0.4803\n","Epoch 2/3 - train_loss: 0.1428 - val_loss: 0.1277 - acc: 0.6342 - f1: 0.5576\n","Epoch 3/3 - train_loss: 0.1318 - val_loss: 0.1252 - acc: 0.5023 - f1: 0.0805\n"]}]},{"cell_type":"markdown","id":"e17cb1a4","metadata":{"id":"e17cb1a4"},"source":["## Summarization\n"]},{"cell_type":"code","execution_count":23,"id":"0434537f","metadata":{"id":"0434537f","executionInfo":{"status":"ok","timestamp":1763789608624,"user_tz":-330,"elapsed":9,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}}},"outputs":[],"source":["def load_sum_dataset():\n","    raw = load_dataset(\"knkarthick/samsum\")\n","    return raw[\"train\"], raw[\"validation\"]"]},{"cell_type":"code","execution_count":24,"id":"5914cb26","metadata":{"id":"5914cb26","executionInfo":{"status":"ok","timestamp":1763789608626,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}}},"outputs":[],"source":["def sum_tokenize(batch, tokenizer):\n","    # T5 expects a task prefix – “summarize: ”\n","    inputs = [\"summarize: \" + doc for doc in batch[\"document\"]]\n","    model_inputs = tokenizer(\n","        inputs,\n","        max_length=512,\n","        truncation=True,\n","        padding=\"max_length\",\n","    )\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            batch[\"summary\"],\n","            max_length=128,\n","            truncation=True,\n","            padding=\"max_length\",\n","        )\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":32,"id":"8cb5603a","metadata":{"id":"8cb5603a","executionInfo":{"status":"ok","timestamp":1763792109353,"user_tz":-330,"elapsed":418,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}}},"outputs":[],"source":["def train_peft_sum(peft_name, peft_cfg, train_ds, eval_ds, out_dir):\n","    tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n","    model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-small\")\n","    model = get_peft_model(model, peft_cfg)\n","    model.print_trainable_parameters()\n","    model.to(device)\n","\n","    args = common_training_args(out_dir)\n","    train_bs = args.per_device_train_batch_size\n","    eval_bs  = args.per_device_eval_batch_size\n","    lr = args.learning_rate\n","    weight_decay = args.weight_decay\n","    num_epochs = int(args.num_train_epochs)\n","\n","    def sum_collator(batch):\n","        inputs = [\"summarize: \" + ex[\"dialogue\"] for ex in batch] # Changed 'document' to 'dialogue'\n","        enc = tokenizer(\n","            inputs,\n","            max_length=512,\n","            truncation=True,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\",\n","        )\n","        with tokenizer.as_target_tokenizer():\n","            labels_tok = tokenizer(\n","                [ex[\"summary\"] for ex in batch],\n","                max_length=128,\n","                truncation=True,\n","                padding=\"max_length\",\n","                return_tensors=\"pt\",\n","            )\n","        labels = labels_tok[\"input_ids\"]\n","        labels[labels == tokenizer.pad_token_id] = -100\n","        enc[\"labels\"] = labels\n","        return enc\n","\n","    from torch.utils.data import DataLoader\n","    train_loader = DataLoader(train_ds, batch_size=train_bs, shuffle=True,  collate_fn=sum_collator)\n","    eval_loader  = DataLoader(eval_ds,  batch_size=eval_bs,  shuffle=False, collate_fn=sum_collator)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    from transformers import get_linear_schedule_with_warmup\n","    total_steps = len(train_loader) * max(1, num_epochs)\n","    warmup_steps = max(0, int(0.1 * total_steps))\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n","\n","    writer = SummaryWriter(log_dir=f\"{out_dir}/runs\")\n","\n","    rouge_metric = evaluate.load(\"rouge\")\n","\n","    for epoch in range(num_epochs):\n","        # ---------------- Train ----------------\n","        model.train()\n","        total_train_loss, n_train = 0.0, 0\n","        for batch in train_loader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            optimizer.zero_grad()\n","            out = model(**batch)\n","            loss = out.loss\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            scheduler.step()\n","            total_train_loss += loss.item() * batch[\"input_ids\"].size(0)\n","            n_train += batch[\"input_ids\"].size(0)\n","        avg_train = total_train_loss / max(1, n_train)\n","\n","        # ---------------- Eval (loss + ROUGE) ----------------\n","        model.eval()\n","        total_eval_loss, n_eval = 0.0, 0\n","        gen_preds, gen_refs = [], []\n","        with torch.no_grad():\n","            for batch in eval_loader:\n","                input_ids_cpu = batch[\"input_ids\"]\n","                attention_mask_cpu = batch[\"attention_mask\"]\n","                labels_cpu = batch[\"labels\"]\n","                batch = {k: v.to(device) for k, v in batch.items()}\n","                out = model(**batch)\n","                loss = out.loss\n","                total_eval_loss += loss.item() * batch[\"input_ids\"].size(0)\n","                n_eval += batch[\"input_ids\"].size(0)\n","                # Generate summaries\n","                gen_ids = model.generate(\n","                    input_ids=input_ids_cpu.to(device),\n","                    attention_mask=attention_mask_cpu.to(device),\n","                    max_length=128,\n","                    num_beams=4,\n","                    length_penalty=1.0,\n","                )\n","                decoded_preds = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n","                # Decode references (remove -100)\n","                for lab_seq in labels_cpu:\n","                    ref_tokens = [t for t in lab_seq.tolist() if t != -100]\n","                    ref_text = tokenizer.decode(ref_tokens, skip_special_tokens=True)\n","                    gen_refs.append(ref_text)\n","                gen_preds.extend(decoded_preds)\n","        avg_eval = total_eval_loss / max(1, n_eval)\n","\n","        rouge_res = rouge_metric.compute(predictions=gen_preds, references=gen_refs, use_stemmer=True)\n","        # Fix: Directly use the float value returned by rouge_metric.compute()\n","        rouge_scores = {k: round(v * 100, 2) for k, v in rouge_res.items() if k in [\"rouge1\", \"rouge2\", \"rougeL\"]}\n","\n","        print(\n","            f\"Epoch {epoch+1}/{num_epochs} - train_loss: {avg_train:.4f} - val_loss: {avg_eval:.4f} \"\n","            + \"- \" + \" - \".join([f\"{rk}: {rv:.2f}\" for rk, rv in rouge_scores.items()])\n","        )\n","        writer.add_scalar(\"train/loss\", avg_train, epoch + 1)\n","        writer.add_scalar(\"val/loss\",   avg_eval,  epoch + 1)\n","        for rk, rv in rouge_scores.items():\n","            writer.add_scalar(f\"val/{rk}\", rv, epoch + 1)\n","        current_lr = scheduler.get_last_lr()[0]\n","        writer.add_scalar(\"lr\", current_lr, epoch + 1)\n","\n","    writer.close()\n","\n","    os.makedirs(out_dir, exist_ok=True)\n","    model.save_pretrained(out_dir)\n","    tokenizer.save_pretrained(out_dir)\n","\n","    return {\"peft\": peft_name, \"eval_loss\": avg_eval, **rouge_scores}\n"]},{"cell_type":"code","execution_count":33,"id":"37a76a32","metadata":{"id":"37a76a32","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763795522405,"user_tz":-330,"elapsed":3408246,"user":{"displayName":"Ruksad siddiqui","userId":"15075578833543186314"}},"outputId":"d9be10c7-3298-456b-aa81-c20b562e5e7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 30,720 || all params: 60,537,344 || trainable%: 0.0507\n","Epoch 1/3 - train_loss: 2.9714 - val_loss: 2.5574 - rouge1: 28.80 - rouge2: 8.24 - rougeL: 22.36\n","Epoch 2/3 - train_loss: 2.8427 - val_loss: 2.4714 - rouge1: 28.03 - rouge2: 7.77 - rougeL: 21.86\n","Epoch 3/3 - train_loss: 2.8029 - val_loss: 2.4497 - rouge1: 27.78 - rouge2: 7.63 - rougeL: 21.67\n","trainable params: 294,912 || all params: 60,801,536 || trainable%: 0.4850\n","Epoch 1/3 - train_loss: 2.1896 - val_loss: 1.8473 - rouge1: 44.65 - rouge2: 21.04 - rougeL: 36.94\n","Epoch 2/3 - train_loss: 2.0124 - val_loss: 1.8102 - rouge1: 44.77 - rouge2: 21.89 - rougeL: 37.62\n","Epoch 3/3 - train_loss: 1.9716 - val_loss: 1.7943 - rouge1: 45.51 - rouge2: 21.94 - rougeL: 37.74\n","trainable params: 122,880 || all params: 60,629,504 || trainable%: 0.2027\n","Epoch 1/3 - train_loss: 2.9593 - val_loss: 2.5110 - rouge1: 19.87 - rouge2: 5.55 - rougeL: 15.79\n","Epoch 2/3 - train_loss: 2.7009 - val_loss: 2.3355 - rouge1: 22.21 - rouge2: 7.07 - rougeL: 17.81\n","Epoch 3/3 - train_loss: 2.6007 - val_loss: 2.2995 - rouge1: 22.78 - rouge2: 7.27 - rougeL: 18.27\n"]}],"source":["train_sum, val_sum = load_sum_dataset()\n","\n","# Prompt‑tuning\n","prompt_cfg_sum = PromptTuningConfig(num_virtual_tokens=30, task_type=\"SEQ_2_SEQ_LM\")\n","sum_prompt = train_peft_sum(\n","    peft_name=\"Prompt\",\n","    peft_cfg=prompt_cfg_sum,\n","    train_ds=train_sum,\n","    eval_ds=val_sum,\n","    out_dir=\"/content/drive/MyDrive/colab_results/sum_prompt\",\n",")\n","\n","# LoRA\n","lora_cfg_sum = LoraConfig(\n","    r=8,\n","    lora_alpha=32,\n","    target_modules=[\"q\", \"v\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"SEQ_2_SEQ_LM\",\n",")\n","sum_lora = train_peft_sum(\n","    peft_name=\"LoRA\",\n","    peft_cfg=lora_cfg_sum,\n","    train_ds=train_sum,\n","    eval_ds=val_sum,\n","    out_dir=\"/content/drive/MyDrive/colab_results/sum_lora\",\n",")\n","\n","# Prefix‑tuning\n","prefix_cfg_sum = PrefixTuningConfig(num_virtual_tokens=20, task_type=\"SEQ_2_SEQ_LM\")\n","sum_prefix = train_peft_sum(\n","    peft_name=\"Prefix\",\n","    peft_cfg=prefix_cfg_sum,\n","    train_ds=train_sum,\n","    eval_ds=val_sum,\n","    out_dir=\"/content/drive/MyDrive/colab_results/sum_prefix\",\n",")"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}