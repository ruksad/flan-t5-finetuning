{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruksad/flan-t5-finetuning/blob/main/24_prefix_tuning_flan_t5_small/flan_t5_peft_performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "52444341",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52444341",
        "outputId": "9e65ed1f-9327-4b0a-e9f6-38bd7ac88f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentencepiece torch evaluate bert-score scikit-learn rouge-score peft datasets accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5b5d44b3",
      "metadata": {
        "id": "5b5d44b3"
      },
      "outputs": [],
      "source": [
        "# Imports and config\n",
        "import os\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from datasets import load_dataset\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f45b5492",
      "metadata": {
        "id": "f45b5492"
      },
      "source": [
        "## Load model and tokenizer\n",
        "We'll use the small FLAN-T5 model to keep things light.\n",
        "- Tokenizer converts text ↔ tokens\n",
        "- Model generates outputs given the tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bfb451b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfb451b4",
        "outputId": "ae292110-ce12-4ba7-a950-6762e23ccaf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"google/flan-t5-small\"\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"device:\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "df2699c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df2699c0",
        "outputId": "d4f1e9b9-b984-41ff-d930-bc03d3d21cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model and tokenizer... This may take a minute\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 6)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-7): 7 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 6)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-7): 7 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "print(\"Loading model and tokenizer... This may take a minute\")\n",
        "from transformers import logging as hf_logging\n",
        "hf_logging.set_verbosity_error()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "297a7685",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "297a7685",
        "outputId": "0ebe0b26-06df-4377-8637-f765830f7887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"dtype\": \"float32\",\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.config )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d7a6667d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7a6667d",
        "outputId": "23acb8c8-f113-450c-954e-d65bc1343621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden size (d_model): 512\n",
            "Encoder layers: 8\n",
            "Decoder layers: 8\n",
            "Number of attention heads: 6\n",
            "Key-value dimension per head: 64\n",
            "Total Q/K/V dimension: 384\n"
          ]
        }
      ],
      "source": [
        "print(f\"Hidden size (d_model): {model.config.d_model}\")\n",
        "print(f\"Encoder layers: {model.config.num_layers}\")\n",
        "print(f\"Decoder layers: {model.config.num_decoder_layers}\")\n",
        "\n",
        "print(f\"Number of attention heads: {model.config.num_heads}\")\n",
        "print(f\"Key-value dimension per head: {model.config.d_kv}\")\n",
        "print(f\"Total Q/K/V dimension: {model.config.num_heads * model.config.d_kv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b1a78e3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1a78e3f",
        "outputId": "10c9be26-d888-4d6c-e943-60d828ecfb37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
            "decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n"
          ]
        }
      ],
      "source": [
        "# See all parameter names\n",
        "for name, param in model.named_parameters():\n",
        "    if 'SelfAttention' in name and 'q' in name:\n",
        "        print(f\"{name}: {param.shape}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "65b6c8d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65b6c8d0",
        "outputId": "fdc6ba9c-6dbe-4592-d8ef-8ccc5d035d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 76,961,152\n",
            "trainable parameters: 76,961,152\n"
          ]
        }
      ],
      "source": [
        "# Total parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params:,}\")  # 76,961,152\n",
        "\n",
        "# trainable parameters\n",
        "trainable = sum(p.numel() for p in model.parameters()\n",
        "                  if p.requires_grad)\n",
        "\n",
        "print(f\"trainable parameters: {trainable:,}\")  # ~6,144,512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5e847aa6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e847aa6",
        "outputId": "0676277d-f7f0-474e-c3c8-39711c2c875a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query weight shape: torch.Size([384, 512])\n",
            "Key weight shape: torch.Size([384, 512])\n",
            "Value weight shape: torch.Size([384, 512])\n",
            "Output weight shape: torch.Size([512, 384])\n"
          ]
        }
      ],
      "source": [
        "# Check a specific attention layer\n",
        "encoder_attn = model.encoder.block[0].layer[0].SelfAttention\n",
        "\n",
        "print(\"Query weight shape:\", encoder_attn.q.weight.shape)  # (384, 512)\n",
        "print(\"Key weight shape:\", encoder_attn.k.weight.shape)    # (384, 512)\n",
        "print(\"Value weight shape:\", encoder_attn.v.weight.shape)  # (384, 512)\n",
        "print(\"Output weight shape:\", encoder_attn.o.weight.shape) # (384, 512)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b2fd642",
      "metadata": {
        "id": "2b2fd642"
      },
      "source": [
        "- Loads SST-2 and SAMSum from Hugging Face datasets.\n",
        "- Runs zero-shot classification on SST-2 using google/flan-t5-small (prompting the model to return exactly one label).\n",
        "- Runs zero-shot summarization on SAMSum (prompting the model for 1–2 sentence summaries).\n",
        "- Evaluates classification (accuracy) and summarization (ROUGE).\n",
        "- Uses small subsets by default so that we can iterate quickly on CPU/GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8d7e1caf",
      "metadata": {
        "id": "8d7e1caf"
      },
      "outputs": [],
      "source": [
        "\n",
        "max_examples = 200\n",
        "# Generation settings\n",
        "GEN_KWARGS_CLASS = {\n",
        "    \"max_length\": 16,\n",
        "    \"num_beams\": 5,\n",
        "    \"early_stopping\": True,\n",
        "    \"do_sample\": False,\n",
        "    \"temperature\": 0.0,\n",
        "}\n",
        "\n",
        "GEN_KWARGS_SUM = {\n",
        "    \"max_length\": 120,\n",
        "    \"num_beams\": 4,\n",
        "    \"early_stopping\": True,\n",
        "    \"do_sample\": False,\n",
        "    \"temperature\": 0.0,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0a374731",
      "metadata": {
        "id": "0a374731"
      },
      "outputs": [],
      "source": [
        "# Utility: normalize model-generated text\n",
        "import unicodedata\n",
        "\n",
        "def normalize_text(s: str):\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    s = s.strip().lower()\n",
        "    # normalize unicode\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    # remove punctuation except spaces\n",
        "    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1ebf84a",
      "metadata": {
        "id": "e1ebf84a"
      },
      "source": [
        "## Zero-shot classification (SST-2 style)\n",
        "FLAN-T5 understands instructions. For SST-2, prompting with `sst2: <text>` often produces `positive` or `negative`.\n",
        "We'll write a tiny helper to classify one or more texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cc835a23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2f5d1d48c24c4461aacd825beea99716",
            "28468aa7792c4b1e9a8fd9cd45138585",
            "748cb74aa15a4a4e8ae95bee079c6d6e",
            "2f4e9a9de36040ca8bb414acd8fbafab",
            "3df45124e98847088427efbe3c8a66aa",
            "b85ca225a5df4b0eb818730b0a730caf",
            "7f8a2ce3056a469cbbc51abd23f02bb7",
            "f8db44ccc26142878c275913ec1584c4",
            "a6503a0f083048008df9e283086dadea",
            "d1afc4748e2f4558b3a5c06052635cd0",
            "543c00f6d78a4e78946101770b5c103a"
          ]
        },
        "id": "cc835a23",
        "outputId": "26b5a3c1-d057-48b7-b337-b79b2c8b3a26"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SST-2 zero-shot:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f5d1d48c24c4461aacd825beea99716"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST-2 zero-shot accuracy on 200 examples: 0.8600\n"
          ]
        }
      ],
      "source": [
        "def zero_shot_sst2_classify(ds,labels=[\"positive\", \"negative\"]):\n",
        "\n",
        "    preds = []\n",
        "    sentence = []\n",
        "    true_labels = [\"negative\" if sentence[\"label\"] == 0 else \"positive\" for sentence in ds]\n",
        "\n",
        "    for ex in tqdm(ds, desc=\"SST-2 zero-shot\"):\n",
        "        text = ex[\"sentence\"]\n",
        "        prompt = (\n",
        "            \"Classify the sentiment of the text as one of the following labels: \"\n",
        "            + \", \".join(labels)\n",
        "            + \".\\n\\n\"\n",
        "            + f\"Text: \\\"{text}\\\"\\n\\nAnswer with exactly one word: \"\n",
        "        )\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(DEVICE)\n",
        "        out = model.generate(**inputs, **GEN_KWARGS_CLASS)\n",
        "        out_text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "        out_text_norm = normalize_text(out_text)\n",
        "\n",
        "        mapped = None\n",
        "        for lab in labels:\n",
        "            if normalize_text(lab) == out_text_norm:\n",
        "                mapped = lab\n",
        "                break\n",
        "        if mapped is None:\n",
        "            for lab in labels:\n",
        "                if normalize_text(lab) in out_text_norm or out_text_norm in normalize_text(lab):\n",
        "                    mapped = lab\n",
        "                    break\n",
        "        if mapped is None:\n",
        "            for lab in labels:\n",
        "                if normalize_text(lab).split()[0] in out_text_norm:\n",
        "                    mapped = lab\n",
        "                    break\n",
        "        if mapped is None:\n",
        "            mapped = labels[0]\n",
        "            print(\"Warning: couldn't map output:\", out_text, \"-> falling back to\", mapped)\n",
        "\n",
        "        preds.append(mapped)\n",
        "        sentence.append(text)\n",
        "\n",
        "    # compute accuracy\n",
        "    acc = sum(1 for p, t in zip(preds, true_labels) if p == t) / len(preds)\n",
        "    print(f\"SST-2 zero-shot accuracy on {len(preds)} examples: {acc:.4f}\")\n",
        "    return {\"sentence\": sentence, \"preds\": preds, \"trues\": true_labels, \"accuracy\": acc}\n",
        "\n",
        "ds = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
        "if max_examples:\n",
        "    ds = ds.select(range(min(len(ds), max_examples)))\n",
        "\n",
        "# Run classification (adjust MAX_EXAMPLES if needed)\n",
        "sst2_res = zero_shot_sst2_classify(ds, labels=[\"positive\", \"negative\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "efbf9f13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efbf9f13",
        "outputId": "2b5eab7f-302a-4637-d5ce-accb0384536f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 sentence:  it 's a charming and often affecting journey .  pred: positive true: positive\n",
            "1 sentence:  unflinchingly bleak and desperate  pred: negative true: negative\n",
            "2 sentence:  allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker .  pred: positive true: positive\n",
            "3 sentence:  the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales .  pred: positive true: positive\n",
            "4 sentence:  it 's slow -- very , very slow .  pred: negative true: negative\n",
            "5 sentence:  although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women .  pred: positive true: positive\n",
            "6 sentence:  a sometimes tedious film .  pred: negative true: negative\n",
            "7 sentence:  or doing last year 's taxes with your ex-wife .  pred: negative true: negative\n",
            "8 sentence:  you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance .  pred: positive true: positive\n",
            "9 sentence:  in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey .  pred: negative true: negative\n",
            "10 sentence:  the mesmerizing performances of the leads keep the film grounded and keep the audience riveted .  pred: positive true: positive\n",
            "11 sentence:  it takes a strange kind of laziness to waste the talents of robert forster , anne meara , eugene levy , and reginald veljohnson all in the same movie .  pred: negative true: negative\n",
            "12 sentence:  ... the film suffers from a lack of humor ( something needed to balance out the violence ) ...  pred: negative true: negative\n",
            "13 sentence:  we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity .  pred: positive true: positive\n",
            "14 sentence:  even horror fans will most likely not find what they 're seeking with trouble every day ; the movie lacks both thrills and humor .  pred: negative true: negative\n",
            "15 sentence:  a gorgeous , high-spirited musical from india that exquisitely blends music , dance , song , and high drama .  pred: positive true: positive\n",
            "16 sentence:  the emotions are raw and will strike a nerve with anyone who 's ever had family trauma .  pred: negative true: positive\n",
            "17 sentence:  audrey tatou has a knack for picking roles that magnify her outrageous charm , and in this literate french comedy , she 's as morning-glory exuberant as she was in amélie .  pred: positive true: positive\n",
            "18 sentence:  ... the movie is just a plain old monster .  pred: negative true: negative\n",
            "19 sentence:  in its best moments , resembles a bad high school production of grease , without benefit of song .  pred: negative true: negative\n"
          ]
        }
      ],
      "source": [
        "# Show a few classification examples\n",
        "for i in range(20):\n",
        "    print(i, \"sentence: \", sst2_res[\"sentence\"][i], \"pred:\", sst2_res[\"preds\"][i], \"true:\", sst2_res[\"trues\"][i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "236a2bae",
      "metadata": {
        "id": "236a2bae"
      },
      "source": [
        "## Classification evaluation (accuracy, precision/recall/f1, confusion matrix, CI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b93f4a6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b93f4a6e",
        "outputId": "d09b935d-f730-4819-a1b1-cd9a5fb2bbf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8600\n",
            "Macro Precision: 0.8625, Macro Recall: 0.8596, Macro F1: 0.8596\n",
            "\n",
            "Per-class (label order = ['negative','positive']):\n",
            "  negative: precision=0.835, recall=0.901, f1=0.867, support=101\n",
            "  positive: precision=0.890, recall=0.818, f1=0.853, support=99\n",
            "\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.8349    0.9010    0.8667       101\n",
            "    positive     0.8901    0.8182    0.8526        99\n",
            "\n",
            "    accuracy                         0.8600       200\n",
            "   macro avg     0.8625    0.8596    0.8596       200\n",
            "weighted avg     0.8622    0.8600    0.8597       200\n",
            "\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            "[[91 10]\n",
            " [18 81]]\n",
            "Accuracy 95% CI (bootstrap): [0.8100, 0.9050]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "import random\n",
        "\n",
        "# preds & trues should be lists from your notebook (sst2_res[\"preds\"], sst2_res[\"trues\"])\n",
        "preds = sst2_res[\"preds\"]\n",
        "trues = sst2_res[\"trues\"]\n",
        "\n",
        "# Basic metrics\n",
        "acc = accuracy_score(trues, preds)\n",
        "precision, recall, f1, support = precision_recall_fscore_support(trues, preds, labels=[\"negative\", \"positive\"], average=None)\n",
        "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(trues, preds, average=\"macro\")\n",
        "\n",
        "print(\"Accuracy: {:.4f}\".format(acc))\n",
        "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(macro_precision, macro_recall, macro_f1))\n",
        "print(\"\\nPer-class (label order = ['negative','positive']):\")\n",
        "for lbl, p, r, f, s in zip([\"negative\",\"positive\"], precision, recall, f1, support):\n",
        "    print(f\"  {lbl}: precision={p:.3f}, recall={r:.3f}, f1={f:.3f}, support={s}\")\n",
        "\n",
        "print(\"\\n\\nClassification report:\")\n",
        "print(classification_report(trues, preds, digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(trues, preds, labels=[\"negative\", \"positive\"])\n",
        "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "print(cm)\n",
        "\n",
        "# Bootstrapped 95% CI for accuracy\n",
        "def bootstrap_confidence_interval(preds, trues, metric_fn, n_boot=1000, alpha=0.05, seed=42):\n",
        "    rng = random.Random(seed)\n",
        "    n = len(preds)\n",
        "    stats = []\n",
        "    for _ in range(n_boot):\n",
        "        idxs = [rng.randrange(n) for _ in range(n)]\n",
        "        p_sample = [preds[i] for i in idxs]\n",
        "        t_sample = [trues[i] for i in idxs]\n",
        "        stats.append(metric_fn(t_sample, p_sample))\n",
        "    stats = np.array(stats)\n",
        "    lo = np.percentile(stats, 100 * (alpha / 2))\n",
        "    hi = np.percentile(stats, 100 * (1 - alpha / 2))\n",
        "    return lo, hi\n",
        "\n",
        "acc_lo, acc_hi = bootstrap_confidence_interval(preds, trues, lambda y_true, y_pred: accuracy_score(y_true, y_pred), n_boot=1000)\n",
        "print(f\"Accuracy 95% CI (bootstrap): [{acc_lo:.4f}, {acc_hi:.4f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597e1b85",
      "metadata": {
        "id": "597e1b85"
      },
      "source": [
        "## Zero-shot summarization\n",
        "For summarization, prefix the input with `summarize:` and provide the content (e.g., a short dialogue)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fa0cdd38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "730d2dc857274f3596e931e045a59acb",
            "c9812929208d40869b2718f9bd7500a7",
            "34ada257c8584feeb6472e9108e3b712",
            "4a1c439b01c345f48dc105543d6ca9b1",
            "e3731e34f28042d3b7bcbab64938bede",
            "667b54dbcd8740448061a39f29b87d8c",
            "ee67202535af4e2783bbd423cc862f7f",
            "f4d501b3243d4d87a0a059b45c2b4db2",
            "a477c8628d5d405e8aa584f2eab731f3",
            "03647853733846a191d337bd1d097a0f",
            "5e0d4ab53f5d44d681d733ba0d9dd4aa"
          ]
        },
        "id": "fa0cdd38",
        "outputId": "e35045c5-06e7-469c-f4a5-90e8afbf5b10"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SAMSum zero-shot:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "730d2dc857274f3596e931e045a59acb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cell: Zero-shot summarization on SAMSum\n",
        "\n",
        "def zero_shot_samsum_summarization(ds_samsum, summary_sentences=(1,2)):\n",
        "\n",
        "\n",
        "    preds = []\n",
        "    refs = []\n",
        "\n",
        "    for ex in tqdm(ds_samsum, desc=\"SAMSum zero-shot\"):\n",
        "        convo = ex[\"dialogue\"]\n",
        "        prompt = (\n",
        "            f\"Summarize the following conversation in {summary_sentences[0]}-{summary_sentences[1]} sentences:\\n\\n\"\n",
        "            + convo\n",
        "            + \"\\n\\nSummary:\"\n",
        "        )\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(DEVICE)\n",
        "        out = model.generate(**inputs, **GEN_KWARGS_SUM)\n",
        "        summary = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "        preds.append(summary.strip())\n",
        "        refs.append(ex[\"summary\"].strip())\n",
        "\n",
        "    return {\"preds\": preds, \"refs\": refs}\n",
        "\n",
        "\n",
        "ds_samsum = load_dataset(\"knkarthick/samsum\", split=\"test\")\n",
        "if max_examples:\n",
        "        ds_samsum = ds_samsum.select(range(min(len(ds_samsum), max_examples)))\n",
        "\n",
        "samsum_res = zero_shot_samsum_summarization(ds_samsum, summary_sentences=(1,2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "190e62db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "190e62db",
        "outputId": "a1ca5d84-0962-44d2-f86f-c3757a2b037c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REF: Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
            "PRED: Larry called Hannah last time they were at the park together. Hannah doesn't know Larry well.\n",
            "------------------------------------------------------------\n",
            "REF: Eric and Rob are going to watch a stand-up on youtube.\n",
            "PRED: Eric and Rob are watching a stand-up on YouTube.\n",
            "------------------------------------------------------------\n",
            "REF: Lenny can't decide which trousers to buy. Bob advised Lenny on that topic. Lenny goes with Bob's advice to pick the trousers that are of best quality.\n",
            "PRED: Bob sends Lenny photos of his trousers. Lenny will buy the first pair or the third pair.\n",
            "------------------------------------------------------------\n",
            "REF: Emma will be home soon and she will let Will know.\n",
            "PRED: Will is going to pick Emma up. Emma will be home soon.\n",
            "------------------------------------------------------------\n",
            "REF: Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\n",
            "PRED: Ollie is in Warsaw. Jane and Ollie have lunch this week. They have lunch on Friday. Ollie will bring some sun with her.\n",
            "------------------------------------------------------------\n",
            "REF: Hilary has the keys to the apartment. Benjamin wants to get them and go take a nap. Hilary is having lunch with some French people at La Cantina. Hilary is meeting them at the entrance to the conference hall at 2 pm. Benjamin and Elliot might join them. They're meeting for the drinks in the evening.\n",
            "PRED: Benjamin, Hilary and Daniel are meeting for drinks in the evening. Hilary and Daniel will go to La Cantina. Hilary will take the keys and take a nap.\n",
            "------------------------------------------------------------\n",
            "REF: Payton provides Max with websites selling clothes. Payton likes browsing and trying on the clothes but not necessarily buying them. Payton usually buys clothes and books as he loves reading.\n",
            "PRED: Max and Payton buy clothes from a lot of sites. Payton likes browsing, looking in the mirror, looking in the mirror and seeing how he looks, but doesn't always buying.\n",
            "------------------------------------------------------------\n",
            "REF: Rita and Tina are bored at work and have still 4 hours left.\n",
            "PRED: Rita is tired. Tina keeps on looking at the clock and there's still 4 hours of boredom.\n",
            "------------------------------------------------------------\n",
            "REF: Beatrice wants to buy Leo a scarf, but he doesn't like scarves. She cares about his health and will buy him a scarf no matter his opinion.\n",
            "PRED: Beatrice doesn't want to buy a scarf because she doesn't have a scarf.\n",
            "------------------------------------------------------------\n",
            "REF: Eric doesn't know if his parents let him go to Ivan's brother's wedding. Ivan will talk to them.\n",
            "PRED: Eric is coming to the wedding with his brother's. Ivan doesn't know if his parents will let him.\n",
            "------------------------------------------------------------\n",
            "REF: Wanda wants to throw a party. She asks Gina to borrow her father's car and go do groceries together. They set the date for Friday.\n",
            "PRED: Wanda and Gina will make a party on Friday.\n",
            "------------------------------------------------------------\n",
            "REF: Martin wrote a short review and won 2 cinema tickets on FB. Martin wants Aggie to go with him this week for the new film with Redford.\n",
            "PRED: Martin won two cinema tickets for the new film with Redford.\n",
            "------------------------------------------------------------\n",
            "REF: Charlee is attending Portuguese theater as a subject at university. He and other students are preparing a play by Mrożek translated into Portuguese.\n",
            "PRED: Charlee is in class. Curtis and Charlee are preparing a performance.\n",
            "------------------------------------------------------------\n",
            "REF: Ella rented a car, this makes things much faster for her and Tom.\n",
            "PRED: Tom and Ella are going by car or train.\n",
            "------------------------------------------------------------\n",
            "REF: Paul is going to share his Netflix account with Luke. In exchange Luke is going to contribute to the subscription. Paul will send Luke his bank details. Paul is on vacation with his girlfriend till tomorrow.\n",
            "PRED: Luke is looking for someone to join netflix family. Luke will send him the login and password on sunday. Luke will send him the bank account details so he can wire him the money every month. Luke is still on holidays with his girl. Luke has been there less than 8 days.\n",
            "------------------------------------------------------------\n",
            "REF: Greg and Betsy have a lot of work today, so they cannot pick up Johnny from the kindergarten. However, it's Greg's turn to do it. Greg will try to find a solution.\n",
            "PRED: Greg and Betsy are going to pick Johnny up. Greg will pick him up on Tuesday.\n",
            "------------------------------------------------------------\n",
            "REF: Ethan, Toby and Marshall are making fun of Scott.\n",
            "PRED: Scott and Toby are enjoying making fun of each other.\n",
            "------------------------------------------------------------\n",
            "REF: Igor has a lot of work on his notice period and he feels demotivated. John thinks he should do what he has to do nevertheless.\n",
            "PRED: Igor is demotivated to give much work to someone on their notice period.\n",
            "------------------------------------------------------------\n",
            "REF: Clara is rewatching Dear White People and strongly recommends it to Neela.\n",
            "PRED: Neela is watching Dear White People on Netflix.\n",
            "------------------------------------------------------------\n",
            "REF: Mike took his car into garage today. Ernest is relieved as someone had just crashed into a red Honda which looks like Mike's.\n",
            "PRED: Ernest parked his car on the street. Mike took it into garage today.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Show a few summarization examples\n",
        "for i in range(20):\n",
        "    print(\"REF:\", samsum_res[\"refs\"][i])\n",
        "    print(\"PRED:\", samsum_res[\"preds\"][i])\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5ae999a",
      "metadata": {
        "id": "f5ae999a"
      },
      "source": [
        "## Summarization evaluation (ROUGE + BERTScore + bootstrap CI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c1770688",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1770688",
        "outputId": "43245c4f-d08d-41c0-8e13-b2dd388c0518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE results (medians / f1 where available):\n",
            "  rouge1: 0.4461\n",
            "  rouge2: 0.1979\n",
            "  rougeL: 0.3663\n",
            "  rougeLsum: 0.3657\n",
            "\n",
            "BERTScore (mean):\n",
            "  precision: 0.7152\n",
            "  recall:    0.6919\n",
            "  f1:        0.7010\n",
            "\n",
            "ROUGE-1 F1 95% CI (bootstrap, n_boot=100): [0.4231, 0.4714]\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# preds and refs from your notebook: samsum_res[\"preds\"], samsum_res[\"refs\"]\n",
        "preds = samsum_res[\"preds\"]\n",
        "refs  = samsum_res[\"refs\"]\n",
        "\n",
        "# ROUGE\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "rouge_res = rouge.compute(predictions=preds, references=refs)\n",
        "print(\"ROUGE results (medians / f1 where available):\")\n",
        "for k, v in rouge_res.items():\n",
        "    # evaluate returns e.g. {'rouge1': 0.4, 'rouge2': 0.2, 'rougeL': 0.37}\n",
        "    print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "# BERTScore\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "bs_res = bertscore.compute(predictions=preds, references=refs, lang=\"en\", model_type=\"microsoft/deberta-xlarge-mnli\")  # model_type optional\n",
        "print(\"\\nBERTScore (mean):\")\n",
        "print(f\"  precision: {np.mean(bs_res['precision']):.4f}\")\n",
        "print(f\"  recall:    {np.mean(bs_res['recall']):.4f}\")\n",
        "print(f\"  f1:        {np.mean(bs_res['f1']):.4f}\")\n",
        "\n",
        "# Bootstrapped CI for ROUGE-1 F1\n",
        "def rouge1_f1(preds_subset, refs_subset):\n",
        "    r = evaluate.load(\"rouge\")\n",
        "    res = r.compute(predictions=preds_subset, references=refs_subset)\n",
        "    return res[\"rouge1\"]\n",
        "\n",
        "def bootstrap_rouge(preds, refs, n_boot=1000, alpha=0.05, seed=42):\n",
        "    rng = random.Random(seed)\n",
        "    n = len(preds)\n",
        "    stats = []\n",
        "    for _ in range(n_boot):\n",
        "        idxs = [rng.randrange(n) for _ in range(n)]\n",
        "        p_sample = [preds[i] for i in idxs]\n",
        "        r_sample = [refs[i] for i in idxs]\n",
        "        stats.append(rouge1_f1(p_sample, r_sample))\n",
        "    stats = np.array(stats)\n",
        "    lo = np.percentile(stats, 100 * (alpha/2))\n",
        "    hi = np.percentile(stats, 100 * (1-alpha/2))\n",
        "    return lo, hi\n",
        "\n",
        "r1_lo, r1_hi = bootstrap_rouge(preds, refs, n_boot=100)  # reduce n_boot for speed on Colab\n",
        "print(f\"\\nROUGE-1 F1 95% CI (bootstrap, n_boot=100): [{r1_lo:.4f}, {r1_hi:.4f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1113dc94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1113dc94",
        "outputId": "78f69885-7a87-4118-afe1-248d3c283126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved readable .txt and JSON files in ./outputs/\n"
          ]
        }
      ],
      "source": [
        "# Save predictions to disk for later analysis\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "def save_outputs(df, dir, file_name):\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "    with open(os.path.join(dir, file_name), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(df, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def format_sst2_readable(res):\n",
        "    lines = [\n",
        "        f\"{i}\\tPRED={p}\\tTRUE={t}\\tSENT={s}\"\n",
        "        for i, (s, p, t) in enumerate(zip(res[\"sentence\"], res[\"preds\"], res[\"trues\"]))\n",
        "    ]\n",
        "    return lines\n",
        "\n",
        "def format_samsum_readable(res):\n",
        "    lines = [\n",
        "        f\"{i}\\nREF: {r}\\nPRED: {p}\\n\" + \"-\"*60\n",
        "        for i, (r, p) in enumerate(zip(res[\"refs\"], res[\"preds\"]))\n",
        "    ]\n",
        "    return lines\n",
        "\n",
        "def write_text(lines, dir, file_name):\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "    with open(os.path.join(dir, file_name), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(lines))\n",
        "\n",
        "# Create readable text versions\n",
        "sst2_readable = format_sst2_readable(sst2_res)\n",
        "samsum_readable = format_samsum_readable(samsum_res)\n",
        "\n",
        "# Write text files\n",
        "write_text(sst2_readable, \"outputs\", \"sst2_preds-zeroshot.txt\")\n",
        "write_text(samsum_readable, \"outputs\", \"samsum_preds-zeroshot.txt\")\n",
        "\n",
        "# Write JSON files\n",
        "save_outputs(sst2_res, \"outputs\", \"sst2_preds-zeroshot.json\")\n",
        "save_outputs(samsum_res, \"outputs\", \"samsum_preds-zeroshot.json\")\n",
        "\n",
        "print(\"Saved readable .txt and JSON files in ./outputs/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities (tokenize helpers + normalization)"
      ],
      "metadata": {
        "id": "wjK-2pz6MncA"
      },
      "id": "wjK-2pz6MncA"
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
        "from peft import PromptTuningConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "# reuse tokenizer and model variables from earlier cells\n",
        "# MODEL_NAME, tokenizer, model, DEVICE already available\n",
        "\n",
        "def make_inputs_for_classification(sentence, labels=[\"positive\",\"negative\"]):\n",
        "    # same prompt style as zero-shot\n",
        "    prompt = (\n",
        "        \"Classify the sentiment of the text as one of the following labels: \"\n",
        "        + \", \".join(labels)\n",
        "        + \".\\n\\n\"\n",
        "        + f\"Text: \\\"{sentence}\\\"\\n\\nAnswer with exactly one word: \"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "def make_inputs_for_summarization(dialogue):\n",
        "    prompt = f\"Summarize the following conversation in 1-2 sentences:\\n\\n{dialogue}\\n\\nSummary:\"\n",
        "    return prompt\n",
        "\n",
        "def tokenize_for_seq2seq(examples, max_input_length=512, max_target_length=64, is_classification=False):\n",
        "    inputs = examples[\"input_text\"] if \"input_text\" in examples else examples[\"text\"]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
        "    # labels are provided as \"target_text\" or \"label_text\"\n",
        "    targets = examples[\"target_text\"]\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    # convert padding token id's of the labels to -100 so they are ignored by the loss\n",
        "    model_inputs[\"labels\"] = [[(l if l != tokenizer.pad_token_id else -100) for l in lab] for lab in model_inputs[\"labels\"]]\n",
        "    return model_inputs\n"
      ],
      "metadata": {
        "id": "81kpfdgFMvEf"
      },
      "id": "81kpfdgFMvEf",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt-tuning on SST-2 (classification)"
      ],
      "metadata": {
        "id": "g4O9X1WhUSCf"
      },
      "id": "g4O9X1WhUSCf"
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
        "from peft import PromptTuningConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "# reuse tokenizer and model variables from earlier cells\n",
        "# MODEL_NAME, tokenizer, model, DEVICE already available\n",
        "\n",
        "def make_inputs_for_classification(sentence, labels=[\"positive\",\"negative\"]):\n",
        "    # same prompt style as zero-shot\n",
        "    prompt = (\n",
        "        \"Classify the sentiment of the text as one of the following labels: \"\n",
        "        + \", \".join(labels)\n",
        "        + \".\\n\\n\"\n",
        "        + f\"Text: \\\"{sentence}\\\"\\n\\nAnswer with exactly one word: \"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "def make_inputs_for_summarization(dialogue):\n",
        "    prompt = f\"Summarize the following conversation in 1-2 sentences:\\n\\n{dialogue}\\n\\nSummary:\"\n",
        "    return prompt\n",
        "\n",
        "def tokenize_for_seq2seq(examples, max_input_length=512, max_target_length=64, is_classification=False):\n",
        "    inputs = examples[\"input_text\"] if \"input_text\" in examples else examples[\"text\"]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
        "    # labels are provided as \"target_text\" or \"label_text\"\n",
        "    targets = examples[\"target_text\"]\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    # convert padding token id's of the labels to -100 so they are ignored by the loss\n",
        "    model_inputs[\"labels\"] = [[(l if l != tokenizer.pad_token_id else -100) for l in lab] for lab in model_inputs[\"labels\"]]\n",
        "    return model_inputs\n",
        "\n",
        "# ---------- Config ----------\n",
        "MAX_EXAMPLES_TRAIN = 100   # training subset size\n",
        "MAX_EXAMPLES_EVAL  = 200    # eval subset size\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 16\n",
        "LR = 1e-4\n",
        "NUM_VIRTUAL_TOKENS = 100     # soft prompt length (tune this)\n",
        "\n",
        "# ---------- Prepare dataset ----------\n",
        "from datasets import load_dataset\n",
        "ds_train = load_dataset(\"glue\", \"sst2\", split=f\"train[:{MAX_EXAMPLES_TRAIN}]\")\n",
        "ds_eval  = load_dataset(\"glue\", \"sst2\", split=f\"validation[:{MAX_EXAMPLES_EVAL}]\")\n",
        "\n",
        "# Prepare text fields for seq2seq training: input_text and target_text\n",
        "def prepare_sst2_seq(ex):\n",
        "    text = make_inputs_for_classification(ex[\"sentence\"], labels=[\"positive\",\"negative\"])\n",
        "    label = \"positive\" if ex[\"label\"] == 1 else \"negative\"\n",
        "    return {\"input_text\": text, \"target_text\": label}\n",
        "\n",
        "ds_train_seq = ds_train.map(prepare_sst2_seq, remove_columns=ds_train.column_names)\n",
        "ds_eval_seq  = ds_eval.map(prepare_sst2_seq, remove_columns=ds_eval.column_names)\n",
        "\n",
        "# Tokenize\n",
        "tokenized_train = ds_train_seq.map(lambda x: tokenize_for_seq2seq(x, max_input_length=256, max_target_length=8), batched=True, remove_columns=ds_train_seq.column_names)\n",
        "tokenized_eval  = ds_eval_seq.map(lambda x: tokenize_for_seq2seq(x, max_input_length=256, max_target_length=8), batched=True, remove_columns=ds_eval_seq.column_names)\n",
        "\n",
        "\n",
        "print(tokenized_train[0][\"labels\"])\n",
        "# Count non -100 tokens per example\n",
        "non_ignored = [sum(1 for t in ex if t != -100) for ex in tokenized_train[\"labels\"]]\n",
        "print(\"Min/Max non-ignored target tokens:\", min(non_ignored), max(non_ignored))\n",
        "\n",
        "\n",
        "# ---------- Setup Prompt Tuning adapter ----------\n",
        "peft_config = PromptTuningConfig(\n",
        "    task_type=\"SEQ_2_SEQ_LM\",\n",
        "    num_virtual_tokens=NUM_VIRTUAL_TOKENS,\n",
        "    prompt_tuning_init=\"random\",   # or \"text\" to initialize from text tokens\n",
        ")\n",
        "\n",
        "# Wrap model with PEFT prompt-tuning\n",
        "model_pt = get_peft_model(model, peft_config)\n",
        "print(\"trainable params \\n\")\n",
        "model_pt.print_trainable_parameters()  # should show only prompt-tuning params\n",
        "\n",
        "# ---------- Training arguments & Trainer ----------\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pt, padding=\"longest\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"outputs/pt_sst2_adapter\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    learning_rate=LR,\n",
        "    fp16=False,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\",\n",
        "    max_grad_norm = 1.0,\n",
        "    report_to=\"none\" # Disable Weights & Biases logging\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_pt,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# ---------- Train ----------\n",
        "trainer.train()\n",
        "torch.autograd.set_detect_anomaly(True) # debuggin for gradient nan\n",
        "# Save the prompt adapter\n",
        "model_pt.push_to_hub = False  # optional: don't push\n",
        "model_pt.save_pretrained(\"outputs/pt_sst2_adapter\")\n",
        "print(\"Saved prompt-tuning adapter to ./outputs/pt_sst2_adapter\")\n",
        "\n",
        "\n",
        "# Run a manual forward pass to see raw loss tensor\n",
        "batch = {k: torch.tensor(v[:2]).to(DEVICE) for k,v in tokenized_train.remove_columns([]).items() if k in [\"input_ids\",\"attention_mask\",\"labels\"]}\n",
        "out = model_pt(**batch)\n",
        "print(\"Manual loss:\", out.loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a98ee29d160d4d999e76713e70dc2f4a",
            "c5cb5ec4dd3c44f5b698d08ba4ad3144",
            "036fd7546f734c0989298817371f4af9",
            "105f052dc61042eb8a5318cf8cc8353d",
            "8bd309818ead459cbfdce98ff05b1d28",
            "c102ec26a38e45c09c0f760f4b8255e1",
            "28dcff6c35a042bca057587926524134",
            "a836a721218c44328b3c8325351d0411",
            "a769ee97cfc6453e8e6636d874f1cdf1",
            "8fef0d8abccb4680bfea7aa328e511bf",
            "b8ed2dcb04a94cc6ab6eb66208545d62",
            "051ee550f8154a1b85531dc47fa91429",
            "eb3f1b4b6cbc4b53915a05a1d87c41f3",
            "d45f11998b554d8e9c1c04bd28004c01",
            "9fed11a547624195963ae4ba400f6cbc",
            "328a611dcdb445bb92e6954f022b6a01",
            "e7ae4b07f7aa4babb874a14cad4f6ce8",
            "d5def88844b949c482bab1d28c0518ae",
            "9d8487fe2cd64d1e82c6821a3aba937f",
            "945f354e3e9c40418d71a58ca2d0cc03",
            "0dae8c614da8400fac5dccd7e64a5812",
            "a11a6efd62e746ee91d67f334857735e",
            "97fc56ee99cf4bf485e82f18e10d528a",
            "93a3ccc985da4b5dac3b357430252aaa",
            "6c397ad584904cd09a22f30c80592a98",
            "4660618c4baf4601a83fa55c2fda301e",
            "d8ff4c0fb1734af6a84beaf78880d420",
            "96067632e0f2423b88da1fd008e998be",
            "db279047329c414389315964dc278d2d",
            "445c021168964017b03522d05d78dbd7",
            "97dfc825c9ad4d758a0fe2d40e501746",
            "c581089c3aaf4824b172bce6666fa514",
            "36b707157b5c4dc99b427100939dd431",
            "2bebd38fb7314b54903f191cfeb078d4",
            "14efda93c451407d9cc9f9110bfe763f",
            "3fee62b0ad7e4da295ac27d079f3862a",
            "63e4e0e92f3e402c9c629d6db01133ad",
            "8d198324ae3d4f018fc6c7ddd218e485",
            "8b68938000de423c968af74ffc6fc5ab",
            "a95ccfd1902c4e21817b7210825bd63e",
            "3844ad56352b430d8896039bc7aa0021",
            "a31d01e8f67d4215bd3f5ba6a1a1cc7d",
            "f5f1da029db3458a80c4212cdb36e111",
            "a071f9edec2f465a85bbde956888e636"
          ]
        },
        "id": "1-mBgpu6UVVR",
        "outputId": "64ca0b3b-99f8-4ab0-fc73-634d61678c10"
      },
      "id": "1-mBgpu6UVVR",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a98ee29d160d4d999e76713e70dc2f4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "051ee550f8154a1b85531dc47fa91429"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97fc56ee99cf4bf485e82f18e10d528a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bebd38fb7314b54903f191cfeb078d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2004348864.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2841, 1, -100, -100, -100, -100, -100, -100]\n",
            "Min/Max non-ignored target tokens: 2 2\n",
            "trainable params \n",
            "\n",
            "trainable params: 102,400 || all params: 77,063,552 || trainable%: 0.1329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: Error detected in LogSoftmaxBackward0. Traceback of forward call that caused the error:\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-2004348864.py\", line 107, in <cell line: 0>\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2325, in train\n",
            "    return inner_training_loop(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2674, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4020, in training_step\n",
            "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4110, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\", line 819, in forward\n",
            "    return model_forward(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\", line 807, in __call__\n",
            "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\", line 2245, in forward\n",
            "    return self.base_model(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\", line 1800, in forward\n",
            "    loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py\", line 1310, in forward\n",
            "    return F.cross_entropy(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 3462, in cross_entropy\n",
            "    return torch._C._nn.cross_entropy_loss(\n",
            " (Triggered internally at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:122.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Function 'LogSoftmaxBackward0' returned nan values in its 0th output.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2004348864.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# ---------- Train ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Save the prompt adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2672\u001b[0m                     )\n\u001b[1;32m   2673\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4069\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4071\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2734\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2737\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Function 'LogSoftmaxBackward0' returned nan values in its 0th output."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference & evaluation of the prompt-tuned SST-2 model\n",
        "\n",
        "- Now run generation using the prompt-tuned model and compute accuracy — then compare with your zero-shot results."
      ],
      "metadata": {
        "id": "9kbri2guMqDQ"
      },
      "id": "9kbri2guMqDQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the prompt-tuned model (it wraps and uses the learned virtual tokens)\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# If you kept model_pt in memory, use it; otherwise:\n",
        "# model_pt = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "# model_pt = get_peft_model(model_pt, peft_config)\n",
        "# model_pt.load_adapter(\"pt_sst2_adapter\")  # If using another saving scheme\n",
        "\n",
        "model_pt.eval()\n",
        "model_pt.to(DEVICE)\n",
        "\n",
        "# Build eval set (same ds_eval_seq used earlier or fresh)\n",
        "eval_ds = load_dataset(\"glue\", \"sst2\", split=f\"validation[:{MAX_EXAMPLES_EVAL}]\")\n",
        "true_labels = [\"positive\" if x[\"label\"]==1 else \"negative\" for x in eval_ds]\n",
        "\n",
        "# Generate predictions\n",
        "preds_pt = []\n",
        "for ex in tqdm(eval_ds, desc=\"SST-2 prompt-tuned inference\"):\n",
        "    prompt = make_inputs_for_classification(ex[\"sentence\"], labels=[\"positive\",\"negative\"])\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=256).to(DEVICE)\n",
        "    out = model_pt.generate(**inputs, max_length=8, num_beams=5, temperature=0.0)\n",
        "    txt = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "    pred = normalize_text(txt)\n",
        "    # map to allowed labels\n",
        "    mapped = None\n",
        "    for lab in [\"positive\",\"negative\"]:\n",
        "        if normalize_text(lab) in pred or pred in normalize_text(lab):\n",
        "            mapped = lab\n",
        "            break\n",
        "    if mapped is None:\n",
        "        mapped = \"positive\"\n",
        "    preds_pt.append(mapped)\n",
        "\n",
        "# Evaluate accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_pt = accuracy_score(true_labels, preds_pt)\n",
        "print(f\"Prompt-tuned SST-2 Accuracy (n={len(preds_pt)}): {acc_pt:.4f}\")\n",
        "\n",
        "# Compare with zero-shot (assuming sst2_res exists)\n",
        "if 'sst2_res' in globals():\n",
        "    print(\"Zero-shot accuracy:\", sst2_res['accuracy'])\n",
        "    print(\"Prompt-tuned accuracy:\", acc_pt)\n",
        "    print(\"Delta (pt - zero):\", acc_pt - sst2_res['accuracy'])\n"
      ],
      "metadata": {
        "id": "P5l4BsJBM18p"
      },
      "id": "P5l4BsJBM18p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGhnhmQA_50W",
        "outputId": "e760f071-746b-4443-81dd-986a88159159"
      },
      "id": "wGhnhmQA_50W",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.57.1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f5d1d48c24c4461aacd825beea99716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28468aa7792c4b1e9a8fd9cd45138585",
              "IPY_MODEL_748cb74aa15a4a4e8ae95bee079c6d6e",
              "IPY_MODEL_2f4e9a9de36040ca8bb414acd8fbafab"
            ],
            "layout": "IPY_MODEL_3df45124e98847088427efbe3c8a66aa"
          }
        },
        "28468aa7792c4b1e9a8fd9cd45138585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b85ca225a5df4b0eb818730b0a730caf",
            "placeholder": "​",
            "style": "IPY_MODEL_7f8a2ce3056a469cbbc51abd23f02bb7",
            "value": "SST-2 zero-shot: 100%"
          }
        },
        "748cb74aa15a4a4e8ae95bee079c6d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8db44ccc26142878c275913ec1584c4",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6503a0f083048008df9e283086dadea",
            "value": 200
          }
        },
        "2f4e9a9de36040ca8bb414acd8fbafab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1afc4748e2f4558b3a5c06052635cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_543c00f6d78a4e78946101770b5c103a",
            "value": " 200/200 [00:38&lt;00:00,  4.08it/s]"
          }
        },
        "3df45124e98847088427efbe3c8a66aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85ca225a5df4b0eb818730b0a730caf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f8a2ce3056a469cbbc51abd23f02bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8db44ccc26142878c275913ec1584c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6503a0f083048008df9e283086dadea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1afc4748e2f4558b3a5c06052635cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "543c00f6d78a4e78946101770b5c103a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "730d2dc857274f3596e931e045a59acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9812929208d40869b2718f9bd7500a7",
              "IPY_MODEL_34ada257c8584feeb6472e9108e3b712",
              "IPY_MODEL_4a1c439b01c345f48dc105543d6ca9b1"
            ],
            "layout": "IPY_MODEL_e3731e34f28042d3b7bcbab64938bede"
          }
        },
        "c9812929208d40869b2718f9bd7500a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667b54dbcd8740448061a39f29b87d8c",
            "placeholder": "​",
            "style": "IPY_MODEL_ee67202535af4e2783bbd423cc862f7f",
            "value": "SAMSum zero-shot: 100%"
          }
        },
        "34ada257c8584feeb6472e9108e3b712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4d501b3243d4d87a0a059b45c2b4db2",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a477c8628d5d405e8aa584f2eab731f3",
            "value": 200
          }
        },
        "4a1c439b01c345f48dc105543d6ca9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03647853733846a191d337bd1d097a0f",
            "placeholder": "​",
            "style": "IPY_MODEL_5e0d4ab53f5d44d681d733ba0d9dd4aa",
            "value": " 200/200 [01:52&lt;00:00,  2.27it/s]"
          }
        },
        "e3731e34f28042d3b7bcbab64938bede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667b54dbcd8740448061a39f29b87d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee67202535af4e2783bbd423cc862f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4d501b3243d4d87a0a059b45c2b4db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a477c8628d5d405e8aa584f2eab731f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03647853733846a191d337bd1d097a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e0d4ab53f5d44d681d733ba0d9dd4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a98ee29d160d4d999e76713e70dc2f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5cb5ec4dd3c44f5b698d08ba4ad3144",
              "IPY_MODEL_036fd7546f734c0989298817371f4af9",
              "IPY_MODEL_105f052dc61042eb8a5318cf8cc8353d"
            ],
            "layout": "IPY_MODEL_8bd309818ead459cbfdce98ff05b1d28"
          }
        },
        "c5cb5ec4dd3c44f5b698d08ba4ad3144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c102ec26a38e45c09c0f760f4b8255e1",
            "placeholder": "​",
            "style": "IPY_MODEL_28dcff6c35a042bca057587926524134",
            "value": "Map: 100%"
          }
        },
        "036fd7546f734c0989298817371f4af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a836a721218c44328b3c8325351d0411",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a769ee97cfc6453e8e6636d874f1cdf1",
            "value": 100
          }
        },
        "105f052dc61042eb8a5318cf8cc8353d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fef0d8abccb4680bfea7aa328e511bf",
            "placeholder": "​",
            "style": "IPY_MODEL_b8ed2dcb04a94cc6ab6eb66208545d62",
            "value": " 100/100 [00:00&lt;00:00, 3896.10 examples/s]"
          }
        },
        "8bd309818ead459cbfdce98ff05b1d28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c102ec26a38e45c09c0f760f4b8255e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28dcff6c35a042bca057587926524134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a836a721218c44328b3c8325351d0411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a769ee97cfc6453e8e6636d874f1cdf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fef0d8abccb4680bfea7aa328e511bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8ed2dcb04a94cc6ab6eb66208545d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "051ee550f8154a1b85531dc47fa91429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb3f1b4b6cbc4b53915a05a1d87c41f3",
              "IPY_MODEL_d45f11998b554d8e9c1c04bd28004c01",
              "IPY_MODEL_9fed11a547624195963ae4ba400f6cbc"
            ],
            "layout": "IPY_MODEL_328a611dcdb445bb92e6954f022b6a01"
          }
        },
        "eb3f1b4b6cbc4b53915a05a1d87c41f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ae4b07f7aa4babb874a14cad4f6ce8",
            "placeholder": "​",
            "style": "IPY_MODEL_d5def88844b949c482bab1d28c0518ae",
            "value": "Map: 100%"
          }
        },
        "d45f11998b554d8e9c1c04bd28004c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8487fe2cd64d1e82c6821a3aba937f",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_945f354e3e9c40418d71a58ca2d0cc03",
            "value": 200
          }
        },
        "9fed11a547624195963ae4ba400f6cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dae8c614da8400fac5dccd7e64a5812",
            "placeholder": "​",
            "style": "IPY_MODEL_a11a6efd62e746ee91d67f334857735e",
            "value": " 200/200 [00:00&lt;00:00, 5159.97 examples/s]"
          }
        },
        "328a611dcdb445bb92e6954f022b6a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ae4b07f7aa4babb874a14cad4f6ce8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5def88844b949c482bab1d28c0518ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d8487fe2cd64d1e82c6821a3aba937f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945f354e3e9c40418d71a58ca2d0cc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0dae8c614da8400fac5dccd7e64a5812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11a6efd62e746ee91d67f334857735e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97fc56ee99cf4bf485e82f18e10d528a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93a3ccc985da4b5dac3b357430252aaa",
              "IPY_MODEL_6c397ad584904cd09a22f30c80592a98",
              "IPY_MODEL_4660618c4baf4601a83fa55c2fda301e"
            ],
            "layout": "IPY_MODEL_d8ff4c0fb1734af6a84beaf78880d420"
          }
        },
        "93a3ccc985da4b5dac3b357430252aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96067632e0f2423b88da1fd008e998be",
            "placeholder": "​",
            "style": "IPY_MODEL_db279047329c414389315964dc278d2d",
            "value": "Map: 100%"
          }
        },
        "6c397ad584904cd09a22f30c80592a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_445c021168964017b03522d05d78dbd7",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97dfc825c9ad4d758a0fe2d40e501746",
            "value": 100
          }
        },
        "4660618c4baf4601a83fa55c2fda301e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c581089c3aaf4824b172bce6666fa514",
            "placeholder": "​",
            "style": "IPY_MODEL_36b707157b5c4dc99b427100939dd431",
            "value": " 100/100 [00:00&lt;00:00, 2076.39 examples/s]"
          }
        },
        "d8ff4c0fb1734af6a84beaf78880d420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96067632e0f2423b88da1fd008e998be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db279047329c414389315964dc278d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "445c021168964017b03522d05d78dbd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97dfc825c9ad4d758a0fe2d40e501746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c581089c3aaf4824b172bce6666fa514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b707157b5c4dc99b427100939dd431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bebd38fb7314b54903f191cfeb078d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14efda93c451407d9cc9f9110bfe763f",
              "IPY_MODEL_3fee62b0ad7e4da295ac27d079f3862a",
              "IPY_MODEL_63e4e0e92f3e402c9c629d6db01133ad"
            ],
            "layout": "IPY_MODEL_8d198324ae3d4f018fc6c7ddd218e485"
          }
        },
        "14efda93c451407d9cc9f9110bfe763f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b68938000de423c968af74ffc6fc5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_a95ccfd1902c4e21817b7210825bd63e",
            "value": "Map: 100%"
          }
        },
        "3fee62b0ad7e4da295ac27d079f3862a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3844ad56352b430d8896039bc7aa0021",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a31d01e8f67d4215bd3f5ba6a1a1cc7d",
            "value": 200
          }
        },
        "63e4e0e92f3e402c9c629d6db01133ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f1da029db3458a80c4212cdb36e111",
            "placeholder": "​",
            "style": "IPY_MODEL_a071f9edec2f465a85bbde956888e636",
            "value": " 200/200 [00:00&lt;00:00, 2661.42 examples/s]"
          }
        },
        "8d198324ae3d4f018fc6c7ddd218e485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b68938000de423c968af74ffc6fc5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95ccfd1902c4e21817b7210825bd63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3844ad56352b430d8896039bc7aa0021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a31d01e8f67d4215bd3f5ba6a1a1cc7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5f1da029db3458a80c4212cdb36e111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a071f9edec2f465a85bbde956888e636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}