{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52444341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip -q install -U \"transformers>=4.44\" \"datasets>=2.20\" \"peft>=0.12\" accelerate evaluate rouge-score scikit-learn sentencepiece \"pyarrow<20.0.0a0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b5d44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and config\n",
    "import os\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b5492",
   "metadata": {},
   "source": [
    "## Load model and tokenizer\n",
    "We'll use the small FLAN-T5 model to keep things light.\n",
    "- Tokenizer converts text ↔ tokens\n",
    "- Model generates outputs given the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfb451b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"google/flan-t5-small\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df2699c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer... This may take a minute\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading model and tokenizer... This may take a minute\")\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "297a7685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 1024,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 8,\n",
      "  \"num_heads\": 6,\n",
      "  \"num_layers\": 8,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7a6667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden size (d_model): 512\n",
      "Encoder layers: 8\n",
      "Decoder layers: 8\n",
      "Number of attention heads: 6\n",
      "Key-value dimension per head: 64\n",
      "Total Q/K/V dimension: 384\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hidden size (d_model): {model.config.d_model}\")  \n",
    "print(f\"Encoder layers: {model.config.num_layers}\")      \n",
    "print(f\"Decoder layers: {model.config.num_decoder_layers}\")  \n",
    "\n",
    "print(f\"Number of attention heads: {model.config.num_heads}\")\n",
    "print(f\"Key-value dimension per head: {model.config.d_kv}\")\n",
    "print(f\"Total Q/K/V dimension: {model.config.num_heads * model.config.d_kv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1a78e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([384, 512])\n"
     ]
    }
   ],
   "source": [
    "# See all parameter names\n",
    "for name, param in model.named_parameters():\n",
    "    if 'SelfAttention' in name and 'q' in name:\n",
    "        print(f\"{name}: {param.shape}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65b6c8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 76,961,152\n",
      "trainable parameters: 76,961,152\n"
     ]
    }
   ],
   "source": [
    "# Total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")  # 76,961,152\n",
    "\n",
    "# trainable parameters\n",
    "trainable = sum(p.numel() for p in model.parameters() \n",
    "                  if p.requires_grad)\n",
    "\n",
    "print(f\"trainable parameters: {trainable:,}\")  # ~6,144,512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e847aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query weight shape: torch.Size([384, 512])\n",
      "Key weight shape: torch.Size([384, 512])\n",
      "Value weight shape: torch.Size([384, 512])\n",
      "Output weight shape: torch.Size([512, 384])\n"
     ]
    }
   ],
   "source": [
    "# Check a specific attention layer\n",
    "encoder_attn = model.encoder.block[0].layer[0].SelfAttention\n",
    "\n",
    "print(\"Query weight shape:\", encoder_attn.q.weight.shape)  # (384, 512)\n",
    "print(\"Key weight shape:\", encoder_attn.k.weight.shape)    # (384, 512)\n",
    "print(\"Value weight shape:\", encoder_attn.v.weight.shape)  # (384, 512)\n",
    "print(\"Output weight shape:\", encoder_attn.o.weight.shape) # (384, 512)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fd642",
   "metadata": {},
   "source": [
    "- Loads SST-2 and SAMSum from Hugging Face datasets.\n",
    "- Runs zero-shot classification on SST-2 using google/flan-t5-small (prompting the model to return exactly one label).\n",
    "- Runs zero-shot summarization on SAMSum (prompting the model for 1–2 sentence summaries).\n",
    "- Evaluates classification (accuracy) and summarization (ROUGE).\n",
    "- Uses small subsets by default so that we can iterate quickly on CPU/GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2c21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b14614cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I absolutely loved this movie. It was fantastic!\n",
      "Prediction: i loved this movie! it was a great\n",
      "\n",
      "Text: The plot was predictable and the acting was bad.\n",
      "Prediction: sst2: the plot was predictable\n",
      "\n",
      "Text: Not great, not terrible.\n",
      "Prediction: sst2: not great, not\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def classify(texts, max_new_tokens=10):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    prompts = [f\"sst2: {t}\" for t in texts]\n",
    "    enc = tokenizer(prompts, return_tensors='pt', padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(**enc, max_new_tokens=max_new_tokens)\n",
    "    decoded = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "    # Normalize a bit for readability\n",
    "    return [d.strip().lower() for d in decoded]\n",
    "\n",
    "examples = [\n",
    "    \"I absolutely loved this movie. It was fantastic!\",\n",
    "    \"The plot was predictable and the acting was bad.\",\n",
    "    \"Not great, not terrible.\"\n",
    "]\n",
    "preds = classify(examples)\n",
    "for t, p in zip(examples, preds):\n",
    "    print(f\"Text: {t}\\nPrediction: {p}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d7e1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_examples = 200\n",
    "# Generation settings\n",
    "GEN_KWARGS_CLASS = {\n",
    "    \"max_length\": 16,\n",
    "    \"num_beams\": 5,\n",
    "    \"early_stopping\": True,\n",
    "    \"do_sample\": False,\n",
    "    \"temperature\": 0.0,\n",
    "}\n",
    "\n",
    "GEN_KWARGS_SUM = {\n",
    "    \"max_length\": 120,\n",
    "    \"num_beams\": 4,\n",
    "    \"early_stopping\": True,\n",
    "    \"do_sample\": False,\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a374731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: normalize model-generated text\n",
    "import unicodedata\n",
    "\n",
    "def normalize_text(s: str):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = s.strip().lower()\n",
    "    # normalize unicode\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    # remove punctuation except spaces\n",
    "    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebf84a",
   "metadata": {},
   "source": [
    "## Zero-shot classification (SST-2 style)\n",
    "FLAN-T5 understands instructions. For SST-2, prompting with `sst2: <text>` often produces `positive` or `negative`.\n",
    "We'll write a tiny helper to classify one or more texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc835a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SST-2 zero-shot: 100%|██████████| 200/200 [00:13<00:00, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 zero-shot accuracy on 200 examples: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def zero_shot_sst2_classify(ds,labels=[\"positive\", \"negative\"]):    \n",
    "\n",
    "    preds = []\n",
    "    sentence = []\n",
    "    true_labels = [\"negative\" if sentence[\"label\"] == 0 else \"positive\" for sentence in ds]\n",
    "\n",
    "    for ex in tqdm(ds, desc=\"SST-2 zero-shot\"):\n",
    "        text = ex[\"sentence\"]\n",
    "        prompt = (\n",
    "            \"Classify the sentiment of the text as one of the following labels: \"\n",
    "            + \", \".join(labels)\n",
    "            + \".\\n\\n\"\n",
    "            + f\"Text: \\\"{text}\\\"\\n\\nAnswer with exactly one word: \"\n",
    "        )\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(DEVICE)\n",
    "        out = model.generate(**inputs, **GEN_KWARGS_CLASS)\n",
    "        out_text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "        out_text_norm = normalize_text(out_text)\n",
    "\n",
    "        mapped = None\n",
    "        for lab in labels:\n",
    "            if normalize_text(lab) == out_text_norm:\n",
    "                mapped = lab\n",
    "                break\n",
    "        if mapped is None:\n",
    "            for lab in labels:\n",
    "                if normalize_text(lab) in out_text_norm or out_text_norm in normalize_text(lab):\n",
    "                    mapped = lab\n",
    "                    break\n",
    "        if mapped is None:\n",
    "            for lab in labels:\n",
    "                if normalize_text(lab).split()[0] in out_text_norm:\n",
    "                    mapped = lab\n",
    "                    break\n",
    "        if mapped is None:\n",
    "            mapped = labels[0]\n",
    "            print(\"Warning: couldn't map output:\", out_text, \"-> falling back to\", mapped)\n",
    "\n",
    "        preds.append(mapped)\n",
    "        sentence.append(text)\n",
    "\n",
    "    # compute accuracy\n",
    "    acc = sum(1 for p, t in zip(preds, true_labels) if p == t) / len(preds)\n",
    "    print(f\"SST-2 zero-shot accuracy on {len(preds)} examples: {acc:.4f}\")\n",
    "    return {\"sentence\": sentence, \"preds\": preds, \"trues\": true_labels, \"accuracy\": acc}\n",
    "\n",
    "ds = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
    "if max_examples:\n",
    "    ds = ds.select(range(min(len(ds), max_examples)))\n",
    "\n",
    "# Run classification (adjust MAX_EXAMPLES if needed)\n",
    "sst2_res = zero_shot_sst2_classify(ds, labels=[\"positive\", \"negative\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efbf9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sentence:  it 's a charming and often affecting journey .  pred: positive true: positive\n",
      "1 sentence:  unflinchingly bleak and desperate  pred: negative true: negative\n",
      "2 sentence:  allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker .  pred: positive true: positive\n",
      "3 sentence:  the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales .  pred: positive true: positive\n",
      "4 sentence:  it 's slow -- very , very slow .  pred: negative true: negative\n",
      "5 sentence:  although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women .  pred: positive true: positive\n",
      "6 sentence:  a sometimes tedious film .  pred: negative true: negative\n",
      "7 sentence:  or doing last year 's taxes with your ex-wife .  pred: negative true: negative\n",
      "8 sentence:  you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance .  pred: positive true: positive\n",
      "9 sentence:  in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey .  pred: negative true: negative\n",
      "10 sentence:  the mesmerizing performances of the leads keep the film grounded and keep the audience riveted .  pred: positive true: positive\n",
      "11 sentence:  it takes a strange kind of laziness to waste the talents of robert forster , anne meara , eugene levy , and reginald veljohnson all in the same movie .  pred: negative true: negative\n",
      "12 sentence:  ... the film suffers from a lack of humor ( something needed to balance out the violence ) ...  pred: negative true: negative\n",
      "13 sentence:  we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity .  pred: positive true: positive\n",
      "14 sentence:  even horror fans will most likely not find what they 're seeking with trouble every day ; the movie lacks both thrills and humor .  pred: negative true: negative\n",
      "15 sentence:  a gorgeous , high-spirited musical from india that exquisitely blends music , dance , song , and high drama .  pred: positive true: positive\n",
      "16 sentence:  the emotions are raw and will strike a nerve with anyone who 's ever had family trauma .  pred: negative true: positive\n",
      "17 sentence:  audrey tatou has a knack for picking roles that magnify her outrageous charm , and in this literate french comedy , she 's as morning-glory exuberant as she was in amélie .  pred: positive true: positive\n",
      "18 sentence:  ... the movie is just a plain old monster .  pred: negative true: negative\n",
      "19 sentence:  in its best moments , resembles a bad high school production of grease , without benefit of song .  pred: negative true: negative\n"
     ]
    }
   ],
   "source": [
    "# Show a few classification examples\n",
    "for i in range(20):\n",
    "    print(i, \"sentence: \", sst2_res[\"sentence\"][i], \"pred:\", sst2_res[\"preds\"][i], \"true:\", sst2_res[\"trues\"][i])\n",
    "\n",
    "examples = [\n",
    "    \"I absolutely loved this movie. It was fantastic!\",\n",
    "    \"The plot was predictable and the acting was bad.\",\n",
    "    \"Not great, not terrible.\"\n",
    "]\n",
    "\n",
    "\n",
    "# preds = classify(examples)\n",
    "# for t, p in zip(examples, preds):\n",
    "#     print(f\"Text: {t}\\nPrediction: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e1b85",
   "metadata": {},
   "source": [
    "## Zero-shot summarization\n",
    "For summarization, prefix the input with `summarize:` and provide the content (e.g., a short dialogue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa0cdd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SAMSum zero-shot: 100%|██████████| 200/200 [01:50<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cell: Zero-shot summarization on SAMSum\n",
    "\n",
    "def zero_shot_samsum_summarization(ds_samsum, summary_sentences=(1,2)):\n",
    "   \n",
    "\n",
    "    preds = []\n",
    "    refs = []\n",
    "\n",
    "    for ex in tqdm(ds_samsum, desc=\"SAMSum zero-shot\"):\n",
    "        convo = ex[\"dialogue\"]\n",
    "        prompt = (\n",
    "            f\"Summarize the following conversation in {summary_sentences[0]}-{summary_sentences[1]} sentences:\\n\\n\"\n",
    "            + convo\n",
    "            + \"\\n\\nSummary:\"\n",
    "        )\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(DEVICE)\n",
    "        out = model.generate(**inputs, **GEN_KWARGS_SUM)\n",
    "        summary = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "        preds.append(summary.strip())\n",
    "        refs.append(ex[\"summary\"].strip())\n",
    "\n",
    "    return {\"preds\": preds, \"refs\": refs}\n",
    "\n",
    "\n",
    "ds_samsum = load_dataset(\"knkarthick/samsum\", split=\"test\")\n",
    "if max_examples:\n",
    "        ds_samsum = ds_samsum.select(range(min(len(ds_samsum), max_examples)))\n",
    "\n",
    "samsum_res = zero_shot_samsum_summarization(ds_samsum, summary_sentences=(1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "190e62db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REF: Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
      "PRED: Larry called Hannah last time they were at the park together. Hannah doesn't know Larry well.\n",
      "------------------------------------------------------------\n",
      "REF: Eric and Rob are going to watch a stand-up on youtube.\n",
      "PRED: Eric and Rob are watching a stand-up on YouTube.\n",
      "------------------------------------------------------------\n",
      "REF: Lenny can't decide which trousers to buy. Bob advised Lenny on that topic. Lenny goes with Bob's advice to pick the trousers that are of best quality.\n",
      "PRED: Bob sends Lenny photos of his trousers. Lenny will buy the first pair or the third pair.\n",
      "------------------------------------------------------------\n",
      "REF: Emma will be home soon and she will let Will know.\n",
      "PRED: Will is going to pick Emma up. Emma will be home soon.\n",
      "------------------------------------------------------------\n",
      "REF: Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\n",
      "PRED: Ollie is in Warsaw. Jane and Ollie have lunch this week. They have lunch on Friday. Ollie will bring some sun with her.\n",
      "------------------------------------------------------------\n",
      "REF: Hilary has the keys to the apartment. Benjamin wants to get them and go take a nap. Hilary is having lunch with some French people at La Cantina. Hilary is meeting them at the entrance to the conference hall at 2 pm. Benjamin and Elliot might join them. They're meeting for the drinks in the evening.\n",
      "PRED: Benjamin, Hilary and Daniel are meeting for drinks in the evening. Hilary and Daniel will go to La Cantina. Hilary will take the keys and take a nap.\n",
      "------------------------------------------------------------\n",
      "REF: Payton provides Max with websites selling clothes. Payton likes browsing and trying on the clothes but not necessarily buying them. Payton usually buys clothes and books as he loves reading.\n",
      "PRED: Max and Payton buy clothes from a lot of sites. Payton likes browsing, looking in the mirror, looking in the mirror and seeing how he looks, but doesn't always buying.\n",
      "------------------------------------------------------------\n",
      "REF: Rita and Tina are bored at work and have still 4 hours left.\n",
      "PRED: Rita is tired. Tina keeps on looking at the clock and there's still 4 hours of boredom.\n",
      "------------------------------------------------------------\n",
      "REF: Beatrice wants to buy Leo a scarf, but he doesn't like scarves. She cares about his health and will buy him a scarf no matter his opinion.\n",
      "PRED: Beatrice doesn't want to buy a scarf because she doesn't have a scarf.\n",
      "------------------------------------------------------------\n",
      "REF: Eric doesn't know if his parents let him go to Ivan's brother's wedding. Ivan will talk to them.\n",
      "PRED: Eric is coming to the wedding with his brother's. Ivan doesn't know if his parents will let him.\n",
      "------------------------------------------------------------\n",
      "REF: Wanda wants to throw a party. She asks Gina to borrow her father's car and go do groceries together. They set the date for Friday.\n",
      "PRED: Wanda and Gina will make a party on Friday.\n",
      "------------------------------------------------------------\n",
      "REF: Martin wrote a short review and won 2 cinema tickets on FB. Martin wants Aggie to go with him this week for the new film with Redford.\n",
      "PRED: Martin won two cinema tickets for the new film with Redford.\n",
      "------------------------------------------------------------\n",
      "REF: Charlee is attending Portuguese theater as a subject at university. He and other students are preparing a play by Mrożek translated into Portuguese.\n",
      "PRED: Charlee is in class. Curtis and Charlee are preparing a performance.\n",
      "------------------------------------------------------------\n",
      "REF: Ella rented a car, this makes things much faster for her and Tom.\n",
      "PRED: Tom and Ella are going by car or train.\n",
      "------------------------------------------------------------\n",
      "REF: Paul is going to share his Netflix account with Luke. In exchange Luke is going to contribute to the subscription. Paul will send Luke his bank details. Paul is on vacation with his girlfriend till tomorrow.\n",
      "PRED: Luke is looking for someone to join netflix family. Luke will send him the login and password on sunday. Luke will send him the bank account details so he can wire him the money every month. Luke is still on holidays with his girl. Luke has been there less than 8 days.\n",
      "------------------------------------------------------------\n",
      "REF: Greg and Betsy have a lot of work today, so they cannot pick up Johnny from the kindergarten. However, it's Greg's turn to do it. Greg will try to find a solution.\n",
      "PRED: Greg and Betsy are going to pick Johnny up. Greg will pick him up on Tuesday.\n",
      "------------------------------------------------------------\n",
      "REF: Ethan, Toby and Marshall are making fun of Scott.\n",
      "PRED: Scott and Toby are enjoying making fun of each other.\n",
      "------------------------------------------------------------\n",
      "REF: Igor has a lot of work on his notice period and he feels demotivated. John thinks he should do what he has to do nevertheless.\n",
      "PRED: Igor is demotivated to give much work to someone on their notice period.\n",
      "------------------------------------------------------------\n",
      "REF: Clara is rewatching Dear White People and strongly recommends it to Neela.\n",
      "PRED: Neela is watching Dear White People on Netflix.\n",
      "------------------------------------------------------------\n",
      "REF: Mike took his car into garage today. Ernest is relieved as someone had just crashed into a red Honda which looks like Mike's.\n",
      "PRED: Ernest parked his car on the street. Mike took it into garage today.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show a few summarization examples\n",
    "for i in range(20):\n",
    "    print(\"REF:\", samsum_res[\"refs\"][i])\n",
    "    print(\"PRED:\", samsum_res[\"preds\"][i])\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1770688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE results (f-measure):\n",
      "rouge1 0.4452036070844183\n",
      "rouge2 0.19870507399527154\n",
      "rougeL 0.3655029081019473\n",
      "rougeLsum 0.3654140327156863\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "rouge_res = rouge.compute(predictions=samsum_res[\"preds\"], references=samsum_res[\"refs\"]) \n",
    "print(\"ROUGE results (f-measure):\")\n",
    "for k, v in rouge_res.items():\n",
    "    # v is a dict with precision/recall/fmeasure when using evaluate\n",
    "    if isinstance(v, dict) and \"f1\" in v:\n",
    "        print(f\"  {k}: {v['f1']:.4f}\")\n",
    "    else:\n",
    "        # compatibility fallback\n",
    "        try:\n",
    "            print(f\" comp  {k}: {v.mid.fmeasure:.4f}\")\n",
    "        except Exception:\n",
    "            print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1113dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved readable .txt and JSON files in ./outputs/\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to disk for later analysis\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def save_outputs(df, dir, file_name):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    with open(os.path.join(dir, file_name), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(df, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def format_sst2_readable(res):\n",
    "    lines = [\n",
    "        f\"{i}\\tPRED={p}\\tTRUE={t}\\tSENT={s}\"\n",
    "        for i, (s, p, t) in enumerate(zip(res[\"sentence\"], res[\"preds\"], res[\"trues\"]))\n",
    "    ]\n",
    "    return lines\n",
    "\n",
    "def format_samsum_readable(res):\n",
    "    lines = [\n",
    "        f\"{i}\\nREF: {r}\\nPRED: {p}\\n\" + \"-\"*60\n",
    "        for i, (r, p) in enumerate(zip(res[\"refs\"], res[\"preds\"]))\n",
    "    ]\n",
    "    return lines\n",
    "\n",
    "def write_text(lines, dir, file_name):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    with open(os.path.join(dir, file_name), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "# Create readable text versions\n",
    "sst2_readable = format_sst2_readable(sst2_res)\n",
    "samsum_readable = format_samsum_readable(samsum_res)\n",
    "\n",
    "# Write text files\n",
    "write_text(sst2_readable, \"outputs\", \"sst2_preds-zeroshot.txt\")\n",
    "write_text(samsum_readable, \"outputs\", \"samsum_preds-zeroshot.txt\")\n",
    "\n",
    "# Write JSON files\n",
    "save_outputs(sst2_res, \"outputs\", \"sst2_preds-zeroshot.json\")\n",
    "save_outputs(samsum_res, \"outputs\", \"samsum_preds-zeroshot.json\")\n",
    "\n",
    "print(\"Saved readable .txt and JSON files in ./outputs/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
